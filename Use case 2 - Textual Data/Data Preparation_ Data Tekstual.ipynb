{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8c28d0",
   "metadata": {},
   "source": [
    "# Data Preparation - Wikipedia Indonesia\n",
    "\n",
    "Notebook ini mendemonstrasikan proses data preparation pada data tekstual.\n",
    "\n",
    "## Alur Proses:\n",
    "1. **Load**: Membaca dan menjelajahi dataset awal\n",
    "2. **Data Cleaning**: Membersihkan markup Wikipedia dan ekstrak kategori\n",
    "3. **Pipeline Processing**: Menerapkan transformasi data secara bertahap\n",
    "4. **Tokenization** : Memecah teks menjadi kunpulan token\n",
    "5. **Vectorization**: Mengkonversi text menjadi TF-IDF matrix\n",
    "6. **Search & Retrieval**: Mencari dokumen paling relevan dengan query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f908548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd6027b",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "Membaca file CSV yang berisi data artikel Wikipedia Indonesia dalam format raw (mentah dengan markup Wiki masih ada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Membaca dataframe (file csv), dengan delimiter pipe (|)\n",
    "df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7c164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-24T00:35:51Z</td>\n",
       "      <td>Asam deoksiribonukleat</td>\n",
       "      <td>[[Berkas:DNA Structure+Key+Labelled.pn NoBB.pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-05-05T11:26:32Z</td>\n",
       "      <td>Anwar Sadat</td>\n",
       "      <td>'''Muhammad Anwar el-Sadat'''; ) adalah seoran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-26T04:25:33Z</td>\n",
       "      <td>Arkeologi</td>\n",
       "      <td>[[Berkas:Bulgandry Aboriginal Site.JPG|jmpl|Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-11-02T02:33:49Z</td>\n",
       "      <td>Antropologi</td>\n",
       "      <td>'''Antropologi''' adalah ilmu tentang manusia....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-11-16T04:21:39Z</td>\n",
       "      <td>Bahasa Indonesia</td>\n",
       "      <td>'''Bahasa Indonesia''' adalah [[bahasa nasiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id             timestamp                   title  \\\n",
       "0           0   1  2022-04-24T00:35:51Z  Asam deoksiribonukleat   \n",
       "1           1   3  2022-05-05T11:26:32Z             Anwar Sadat   \n",
       "2           2   5  2022-09-26T04:25:33Z               Arkeologi   \n",
       "3           3   6  2022-11-02T02:33:49Z             Antropologi   \n",
       "4           4   8  2022-11-16T04:21:39Z        Bahasa Indonesia   \n",
       "\n",
       "                                                text  \n",
       "0  [[Berkas:DNA Structure+Key+Labelled.pn NoBB.pn...  \n",
       "1  '''Muhammad Anwar el-Sadat'''; ) adalah seoran...  \n",
       "2  [[Berkas:Bulgandry Aboriginal Site.JPG|jmpl|Si...  \n",
       "3  '''Antropologi''' adalah ilmu tentang manusia....  \n",
       "4  '''Bahasa Indonesia''' adalah [[bahasa nasiona...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#menampilkan dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c85bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86436 entries, 0 to 86435\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  86436 non-null  int64 \n",
      " 1   id          86436 non-null  int64 \n",
      " 2   timestamp   86436 non-null  object\n",
      " 3   title       86436 non-null  object\n",
      " 4   text        86436 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#meilhat informasi umum dari dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89ac03",
   "metadata": {},
   "source": [
    "#### Melihat contoh isi `teks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "720ba1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menampilkan contoh isi data teks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ba719",
   "metadata": {},
   "source": [
    "## 4.Data Cleaning and Extraction\n",
    "\n",
    "Membersihkan text dari markup Wikipedia dan mengekstrak informasi.\n",
    "**Fungsi Utama:**\n",
    "- Ekstrak kategori dari format `[[Kategori:...]]`\n",
    "- Pembersihan teks lengkap (hapus ref, link, template, dsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "546b4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengambil 1 sampel text sebagai contoh\n",
    "sample_text = df.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a78ab1",
   "metadata": {},
   "source": [
    "### 4.1 Esktrak informasi kategori\n",
    "\n",
    "`[[Kategori:Genetika molekular|Nukleat asam DNA]]`\n",
    "\n",
    "`[[Kategori:Asam nukleat]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bda3633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genetika molekular', 'Nukleat asam DNA', 'Asam nukleat']\n"
     ]
    }
   ],
   "source": [
    "# mencari dan mengekstrak informasi kategori artikel dari teks\n",
    "x = re.findall(r'\\[\\[Kategori:(.*?)\\]\\]', sample_text)\n",
    "kategori_extracted = []\n",
    "for kategori in x:\n",
    "    kategori_extracted.extend(kategori.split('|'))\n",
    "print(kategori_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3397cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modularisasi ke bentuk fungsi, agar lebih mudah digunakan pada dataframe\n",
    "def extract_kategori(text):\n",
    "    x = re.findall(r'\\[\\[Kategori:(.*?)\\]\\]',text)\n",
    "    kategori_extracted = []\n",
    "    for kategori in x:\n",
    "        kategori_extracted.extend(kategori.split('|'))\n",
    "    return kategori_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c00f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Genetika molekular', 'Nukleat asam DNA', 'Asam nukleat']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menjalankan fungsi terhadap sample_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368225c",
   "metadata": {},
   "source": [
    "### 4.2 Membersihkan/ Menghapus markdown files\n",
    "`[[Berkas:DNA animation.gif|jmpl|Gambaran tiga dimensi DNA]]{{genetika}}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a7d6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mencari dan menghapus semua markdown files\n",
    "sample_text_clean = re.sub(r'\\[\\[Berkas:.*?\\n','', sample_text, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6df5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan hasil cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6946c01b",
   "metadata": {},
   "source": [
    "### 4.3 Membersihkan/Menghapus reftag\n",
    "`<ref>{{cite book|last = Saenger|first = Wolfram|title = Principles of Nucleic Acid Structure|url = https://archive.org/details/...\n",
    "}}</ref>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1603ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mencari dan menghapus semua reftag\n",
    "sample_text_clean = re.sub(r'<ref.*?<\\/ref>', '', sample_text_clean, flags=re.DOTALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe86d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan hasil cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8f55f",
   "metadata": {},
   "source": [
    "### 4.4 Membersihkan internal link\n",
    "\n",
    "`[[Hereditas|pewarisan]]` akan  menjadi `pewarisan` (hanya mengambil labelnya saja)\n",
    "\n",
    "`[[kromosom]]` akan menjadu `kromosom`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleansing internal link dengan label\n",
    "sample_text_clean = re.sub(r'\\[\\[[\\w\\s]*?\\|([\\w\\s]*?)\\]\\]',r'\\1', sample_text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleansing internal link tanpa label\n",
    "sample_text_clean = re.sub(r'\\[\\[([\\w\\s]*)\\]\\]', r'\\1', sample_text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan hasil cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f93cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_text(text):\n",
    "    text = re.sub(r'\\[\\[(Berkas|File).*?\\n',' ',text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'<ref.*?<\\/ref>', ' ', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'\\[\\[[\\w\\s]*?\\|([\\w\\s]*?)\\]\\]',r'\\1',text)\n",
    "    text = re.sub(r'\\[\\[(.*?)\\]\\]', r'\\1', text)\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d262898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mencoba fungsi pada sample_text dan membandingkan hasil sebelum dan sesudah cleansing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8eadbd",
   "metadata": {},
   "source": [
    "## 5. Eksekusi Data Cleaning Pipeline\n",
    "\n",
    "Menerapkan semua fungsi pembersihan secara berurutan menggunakan method chaining `.pipe()`.\n",
    "\n",
    "Output: `df_cleaned` - Dataset yang sudah bersih dengan kolom text_cleaned dan kategori\n",
    "\n",
    "**Fungsi Pipeline:**\n",
    "- `start_pipeline()`: Mulai pipeline\n",
    "- `extract_kategori_pipe()`:  ekstraksi kategori\n",
    "- `clean_text_pipe()`:  pembersihan text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pipeline\n",
    "def start_pipeline(df):\n",
    "    return df.copy()\n",
    "\n",
    "def extract_kategori_pipe(df):\n",
    "    df['kategori'] = df['text'].apply(extract_kategori)\n",
    "    return df\n",
    "\n",
    "def cleanse_text_pipe(df):\n",
    "    df['text_cleaned'] = df['text'].apply(cleanse_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bca2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 86436 entries, 0 to 86435\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    86436 non-null  int64 \n",
      " 1   id            86436 non-null  int64 \n",
      " 2   timestamp     86436 non-null  object\n",
      " 3   title         86436 non-null  object\n",
      " 4   text          86436 non-null  object\n",
      " 5   text_cleaned  86436 non-null  object\n",
      " 6   kategori      86436 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 4.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#menjalankan proses pembersihan pada dataframe\n",
    "df_cleaned = (df\n",
    "              .pipe(start_pipeline)\n",
    "              .pipe(extract_kategori_pipe)\n",
    "              .pipe(cleanse_text_pipe)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2e2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>kategori</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-24T00:35:51Z</td>\n",
       "      <td>Asam deoksiribonukleat</td>\n",
       "      <td>[[Berkas:DNA Structure+Key+Labelled.pn NoBB.pn...</td>\n",
       "      <td>Asam deoksiribonukleat     lebih dikenal denga...</td>\n",
       "      <td>[Genetika molekular, Nukleat asam DNA, Asam nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-05-05T11:26:32Z</td>\n",
       "      <td>Anwar Sadat</td>\n",
       "      <td>'''Muhammad Anwar el-Sadat'''; ) adalah seoran...</td>\n",
       "      <td>Muhammad Anwar el Sadat       adalah seorang p...</td>\n",
       "      <td>[Presiden Mesir, Perdana Menteri Mesir, Pemena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-26T04:25:33Z</td>\n",
       "      <td>Arkeologi</td>\n",
       "      <td>[[Berkas:Bulgandry Aboriginal Site.JPG|jmpl|Si...</td>\n",
       "      <td>Arkeologi    atau    ilmu kepurbakalaan     ad...</td>\n",
       "      <td>[Arkeologi,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-11-02T02:33:49Z</td>\n",
       "      <td>Antropologi</td>\n",
       "      <td>'''Antropologi''' adalah ilmu tentang manusia....</td>\n",
       "      <td>Antropologi    adalah ilmu tentang manusia  An...</td>\n",
       "      <td>[Antropologi,  ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-11-16T04:21:39Z</td>\n",
       "      <td>Bahasa Indonesia</td>\n",
       "      <td>'''Bahasa Indonesia''' adalah [[bahasa nasiona...</td>\n",
       "      <td>Bahasa Indonesia    adalah bahasa nasional dan...</td>\n",
       "      <td>[Bahasa Indonesia,  , Bahasa di Indonesia, Bah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86431</th>\n",
       "      <td>86431</td>\n",
       "      <td>3768250</td>\n",
       "      <td>2022-11-19T13:16:22Z</td>\n",
       "      <td>Qatar pada Piala Dunia FIFA</td>\n",
       "      <td>[[Tim nasional sepak bola  Qatar]] tidak perna...</td>\n",
       "      <td>Tim nasional sepak bola  Qatar tidak pernah lo...</td>\n",
       "      <td>[Qatar pada Piala Dunia FIFA,  , Negara pada P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86432</th>\n",
       "      <td>86432</td>\n",
       "      <td>3768386</td>\n",
       "      <td>2022-11-20T04:25:50Z</td>\n",
       "      <td>Bahasa Ma'ya</td>\n",
       "      <td>'''Bahasa Ma'ya''' adalah [[Bahasa Austronesia...</td>\n",
       "      <td>Bahasa Ma ya    adalah Bahasa Austronesia dari...</td>\n",
       "      <td>[Rumpun bahasa Halmahera Selatan–New Guinea Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86433</th>\n",
       "      <td>86433</td>\n",
       "      <td>3768388</td>\n",
       "      <td>2022-11-20T04:35:20Z</td>\n",
       "      <td>Nabeul</td>\n",
       "      <td>'''Nabeul (;  )''' merupakan kota pesisir yang...</td>\n",
       "      <td>Nabeul          merupakan kota pesisir yang te...</td>\n",
       "      <td>[Permukiman di Tunisia, CS1 sumber berbahasa P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86434</th>\n",
       "      <td>86434</td>\n",
       "      <td>3768419</td>\n",
       "      <td>2022-11-20T07:41:32Z</td>\n",
       "      <td>Porsche 963</td>\n",
       "      <td>'''Porsche 963''' adalah mobil balap prototipe...</td>\n",
       "      <td>Porsche 963    adalah mobil balap prototipe ol...</td>\n",
       "      <td>[Mobil balap Le Mans 24 Jam, Prototipe olahrag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86435</th>\n",
       "      <td>86435</td>\n",
       "      <td>3768435</td>\n",
       "      <td>2022-11-20T08:26:08Z</td>\n",
       "      <td>Toyota GR010 Hybrid</td>\n",
       "      <td>'''Toyota GR010 Hybrid''' adalah mobil balap p...</td>\n",
       "      <td>Toyota GR010 Hybrid    adalah mobil balap prot...</td>\n",
       "      <td>[Mobil balap Toyota, Le Mans Hypercar, Mobil p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86436 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0       id             timestamp                        title  \\\n",
       "0               0        1  2022-04-24T00:35:51Z       Asam deoksiribonukleat   \n",
       "1               1        3  2022-05-05T11:26:32Z                  Anwar Sadat   \n",
       "2               2        5  2022-09-26T04:25:33Z                    Arkeologi   \n",
       "3               3        6  2022-11-02T02:33:49Z                  Antropologi   \n",
       "4               4        8  2022-11-16T04:21:39Z             Bahasa Indonesia   \n",
       "...           ...      ...                   ...                          ...   \n",
       "86431       86431  3768250  2022-11-19T13:16:22Z  Qatar pada Piala Dunia FIFA   \n",
       "86432       86432  3768386  2022-11-20T04:25:50Z                 Bahasa Ma'ya   \n",
       "86433       86433  3768388  2022-11-20T04:35:20Z                       Nabeul   \n",
       "86434       86434  3768419  2022-11-20T07:41:32Z                  Porsche 963   \n",
       "86435       86435  3768435  2022-11-20T08:26:08Z          Toyota GR010 Hybrid   \n",
       "\n",
       "                                                    text  \\\n",
       "0      [[Berkas:DNA Structure+Key+Labelled.pn NoBB.pn...   \n",
       "1      '''Muhammad Anwar el-Sadat'''; ) adalah seoran...   \n",
       "2      [[Berkas:Bulgandry Aboriginal Site.JPG|jmpl|Si...   \n",
       "3      '''Antropologi''' adalah ilmu tentang manusia....   \n",
       "4      '''Bahasa Indonesia''' adalah [[bahasa nasiona...   \n",
       "...                                                  ...   \n",
       "86431  [[Tim nasional sepak bola  Qatar]] tidak perna...   \n",
       "86432  '''Bahasa Ma'ya''' adalah [[Bahasa Austronesia...   \n",
       "86433  '''Nabeul (;  )''' merupakan kota pesisir yang...   \n",
       "86434  '''Porsche 963''' adalah mobil balap prototipe...   \n",
       "86435  '''Toyota GR010 Hybrid''' adalah mobil balap p...   \n",
       "\n",
       "                                            text_cleaned  \\\n",
       "0      Asam deoksiribonukleat     lebih dikenal denga...   \n",
       "1      Muhammad Anwar el Sadat       adalah seorang p...   \n",
       "2      Arkeologi    atau    ilmu kepurbakalaan     ad...   \n",
       "3      Antropologi    adalah ilmu tentang manusia  An...   \n",
       "4      Bahasa Indonesia    adalah bahasa nasional dan...   \n",
       "...                                                  ...   \n",
       "86431  Tim nasional sepak bola  Qatar tidak pernah lo...   \n",
       "86432  Bahasa Ma ya    adalah Bahasa Austronesia dari...   \n",
       "86433  Nabeul          merupakan kota pesisir yang te...   \n",
       "86434  Porsche 963    adalah mobil balap prototipe ol...   \n",
       "86435  Toyota GR010 Hybrid    adalah mobil balap prot...   \n",
       "\n",
       "                                                kategori  \n",
       "0      [Genetika molekular, Nukleat asam DNA, Asam nu...  \n",
       "1      [Presiden Mesir, Perdana Menteri Mesir, Pemena...  \n",
       "2                                         [Arkeologi,  ]  \n",
       "3                                       [Antropologi,  ]  \n",
       "4      [Bahasa Indonesia,  , Bahasa di Indonesia, Bah...  \n",
       "...                                                  ...  \n",
       "86431  [Qatar pada Piala Dunia FIFA,  , Negara pada P...  \n",
       "86432  [Rumpun bahasa Halmahera Selatan–New Guinea Ba...  \n",
       "86433  [Permukiman di Tunisia, CS1 sumber berbahasa P...  \n",
       "86434  [Mobil balap Le Mans 24 Jam, Prototipe olahrag...  \n",
       "86435  [Mobil balap Toyota, Le Mans Hypercar, Mobil p...  \n",
       "\n",
       "[86436 rows x 7 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menampilkan hasil cleansing dan ekstraksi pada dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9695f2",
   "metadata": {},
   "source": [
    "## 6. Feature Extraction\n",
    "\n",
    "- **Tokenisasi** : Merubah teks utuh menjadi komponen-komponen token\n",
    "- **Vektorisasi**: Mengkonversi text menjadi numerical feature menggunakan TF-IDF (Term Frequency-Inverse Document \n",
    "\n",
    "**Output**: TF-IDF matrix - menghasilkan matrix yang merupakan representasi numerik dari setiap teks/dookumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d781a",
   "metadata": {},
   "source": [
    "### 6.1 Tokenisasi\n",
    "\n",
    "#### Mengapa Tokenisasi Penting?\n",
    "\n",
    "1. **Pemrosesan Komputer**: Algoritma machine learning memerlukan input yang terstruktur. Tokenisasi mengubah teks yang tidak terstruktur menjadi deretan token yang dapat dianalisis secara sistematis.\n",
    "\n",
    "2. **Pengurangan Kompleksitas**: Memecah teks besar menjadi satuan kecil memudahkan pemrosesan dan analisis yang lebih efisien.\n",
    "\n",
    "3. **Ekstraksi Fitur**: Token individual menjadi basis untuk ekstraksi fitur lanjutan seperti TF-IDF, word embeddings, dan analisis frekuensi.\n",
    "\n",
    "#### Contoh Tokenisasi Sederhana (Word-Level Tokenization)\n",
    "\n",
    "Teks asli:\n",
    "```\n",
    "\"Indonesia adalah negara kepulauan terbesar di dunia yang terletak di Asia Tenggara\"\n",
    "```\n",
    "\n",
    "Setelah tokenisasi dengan memisahkan berdasarkan spasi:\n",
    "```\n",
    "['Indonesia', 'adalah', 'negara', 'kepulauan', 'terbesar', 'di', 'dunia', 'yang', 'terletak', 'di', 'Asia', 'Tenggara']\n",
    "```\n",
    "\n",
    "Jumlah token: **12 token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad54075c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Indonesia',\n",
       " 'adalah',\n",
       " 'negara',\n",
       " 'kepulauan',\n",
       " 'terbesar',\n",
       " 'di',\n",
       " 'dunia',\n",
       " 'yang',\n",
       " 'terletak',\n",
       " 'di',\n",
       " 'Asia',\n",
       " 'Tenggara']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple tokenization\n",
    "sample_text = 'Indonesia adalah negara kepulauan terbesar di dunia yang terletak di Asia Tenggara'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mencoba tokenisasi sederhana (word level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c8558",
   "metadata": {},
   "source": [
    "### 6.2 Vektorisasi Teks (Text Vectorization)\n",
    "\n",
    "**Vektorisasi** adalah proses fundamental dalam *Natural Language Processing* (NLP) untuk mengubah data teks tidak terstruktur menjadi representasi numerik (vektor) yang dapat dipahami oleh mesin.\n",
    "\n",
    "Bayangkan vektorisasi sebagai **penerjemah**: Komputer tidak mengerti kata \"Apel\" atau \"Jeruk\", tetapi mereka mengerti bahwa `[1, 0]` berbeda dengan `[0, 1]`.\n",
    "\n",
    "#### Mengapa Vektorisasi Penting?\n",
    "\n",
    "Komputer bekerja dengan operasi aljabar linier. Tanpa vektorisasi, algoritma machine learning tidak dapat memproses input teks.\n",
    "1.  **Kompatibilitas Matematis**: Algoritma seperti Regresi, SVM, atau Neural Networks membutuhkan input berupa array angka (matriks).\n",
    "2.  **Menangkap Makna (Semantik)**: Teknik vektorisasi yang baik tidak hanya mengubah kata jadi angka, tapi juga mempertahankan informasi penting seperti seberapa unik kata tersebut dalam sebuah dokumen.\n",
    "3.  **Pengukuran Jarak**: Memungkinkan kita menghitung *similarity* (kemiripan) antar dokumen menggunakan rumus geometri seperti *Cosine Similarity* atau *Euclidean Distance*.\n",
    "\n",
    "---\n",
    "\n",
    "#### Beberapa Metode Vektorisasi\n",
    "\n",
    "Berikut adalah beberapa pendekatan populer, diurutkan dari yang paling sederhana hingga metode yang kami pilih:\n",
    "\n",
    "##### 1. One-Hot Encoding\n",
    "Setiap kata dalam *vocabulary* diwakili oleh satu bit unik.\n",
    "* **Konsep**: Jika kita memiliki 1.000 kata unik, setiap kata adalah vektor sepanjang 1.000 dimensi dengan satu angka `1` dan sisanya `0`.\n",
    "* **Kelemahan**: Menghasilkan dimensi yang sangat besar (*high dimensionality*) dan tidak menangkap frekuensi kata.\n",
    "\n",
    "##### 2. Bag of Words (BoW) / Count Vectorizer\n",
    "Metode ini menghitung **frekuensi** kemunculan kata dalam dokumen tanpa memperdulikan urutan.\n",
    "* **Analogi**: Bayangkan sebuah dokumen dipotong-potong per kata, lalu dimasukkan ke dalam kantong (bag). Kita hanya menghitung jumlah kata \"makan\" ada berapa, \"tidur\" ada berapa.\n",
    "* **Kelemahan**: Kata umum seperti \"yang\", \"dan\", \"di\" akan memiliki nilai (bobot) yang sangat besar, padahal kata-kata tersebut minim informasi unik.\n",
    "\n",
    "##### 3. TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "Metode ini adalah penyempurnaan dari BoW. TF-IDF memberikan bobot pada kata berdasarkan dua prinsip:\n",
    "1.  **Seberapa sering** kata muncul di dokumen ini? (TF)\n",
    "2.  **Seberapa jarang** kata muncul di seluruh koleksi dokumen lain? (IDF)\n",
    "\n",
    "Tujuannya adalah menonjolkan kata yang **sering muncul di satu dokumen tertentu, tapi jarang muncul di dokumen lain** .\n",
    "\n",
    "---\n",
    "\n",
    "#### Algoritma TF-IDF\n",
    "\n",
    "Rumus matematis untuk menghitung bobot kata $t$ dalam dokumen $d$:\n",
    "\n",
    "$$W_{t,d} = \\text{TF}(t,d) \\times \\text{IDF}(t)$$\n",
    "\n",
    "Dimana:\n",
    "\n",
    "1.  **Term Frequency (TF)**: Frekuensi kata dalam dokumen tertentu.\n",
    "    $$\\text{TF}(t,d) = \\frac{\\text{Jumlah kemunculan kata } t \\text{ di dokumen } d}{\\text{Total kata dalam dokumen } d}$$\n",
    "\n",
    "2.  **Inverse Document Frequency (IDF)**: Mengukur seberapa informatif sebuah kata.\n",
    "    $$\\text{IDF}(t) = \\log \\left( \\frac{\\text{Total Dokumen } (N)}{\\text{Jumlah Dokumen yang mengandung kata } t} \\right)$$\n",
    "\n",
    "**Simulasi Perhitungan Sederhana:**\n",
    "\n",
    "Misalkan kita memiliki data teks:\n",
    "* **Doc A**: \"Kucing makan ikan\"\n",
    "* **Doc B**: \"Kucing tidur\"\n",
    "* **Doc C**: \"Ikan berenang\"\n",
    "\n",
    "Nilai bobot untuk kata **\"Kucing\"** di **Doc A**:\n",
    "\n",
    "1.  **TF (\"Kucing\", Doc A)**: Muncul 1 kali dari 3 total kata = $1/3 \\approx 0.33$\n",
    "2.  **IDF (\"Kucing\")**: Muncul di 2 dokumen (A & B) dari total 3 dokumen.\n",
    "    $$\\text{IDF} = \\log(3/2) \\approx 0.176$$\n",
    "3.  **TF-IDF**: $0.33 \\times 0.176 = \\mathbf{0.058}$\n",
    "\n",
    "Bandingkan dengan kata **\"Berenang\"** di **Doc C**:\n",
    "1.  **TF**: $1/2 = 0.5$\n",
    "2.  **IDF**: Muncul hanya di 1 dokumen. $\\log(3/1) \\approx 0.477$\n",
    "3.  **TF-IDF**: $0.5 \\times 0.477 = \\mathbf{0.238}$\n",
    "\n",
    "> **Insight**: Kata \"Berenang\" memiliki bobot lebih tinggi daripada \"Kucing\" karena \"Berenang\" lebih spesifik/langka dalam koleksi dokumen ini.\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Vektorisasi: Sparse Matrix\n",
    "\n",
    "Hasil dari proses ini adalah sebuah matriks di mana:\n",
    "* **Baris**: Dokumen (Artikel Wikipedia)\n",
    "* **Kolom**: Kata (Fitur/Vocabulary)\n",
    "* **Nilai**: Skor TF-IDF\n",
    "\n",
    "Karena sebagian besar kata tidak muncul di setiap dokumen, matriks ini akan didominasi oleh angka nol. Untuk menghemat memori, ini disimpan sebagai **Sparse Matrix**.\n",
    "\n",
    "**Ilustrasi Matriks TF-IDF:**\n",
    "\n",
    "| Dokumen | 'indonesia' | 'adalah' | 'kepulauan' | 'teknologi' | 'ekonomi' |\n",
    "| :--- | :---: | :---: | :---: | :---: | :---: |\n",
    "| **Artikel 1** | 0.45 | 0.02 | 0.65 | 0.00 | 0.00 |\n",
    "| **Artikel 2** | 0.00 | 0.02 | 0.00 | 0.55 | 0.35 |\n",
    "| **Artikel 3** | 0.30 | 0.01 | 0.00 | 0.00 | 0.75 |\n",
    "\n",
    "*Catatan: Nilai 0.00 merepresentasikan kata tersebut tidak ada dalam dokumen.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76293859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dee524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat daftar stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc9155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 43873033 stored elements and shape (86436, 50000)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vektorisasi menggunakan TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f0e934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(21615)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mlihat daftar vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melakukan fitting vectorizer pada data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906af67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.84515274)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melihat representasi nilai sebuah sampel token pada dokumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc1e0a",
   "metadata": {},
   "source": [
    "### 6.3 Simulasi Search and Retreival Sederhana\n",
    "\n",
    "Mencoba menemukan dokumen yang paling relevan berdasarkan query (kata kunci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac9186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 3 stored elements and shape (1, 50000)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query\n",
    "query =  ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f464eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#melakukan tranformasi pada query (tokenisasi dan vektorisasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc744912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#menghitung kemiripan query ke kumpulan dokumen\n",
    "similarity = cosine_similarity(..., ...)\n",
    "\n",
    "# top 10 dokumen yang paling mirip\n",
    "top_10_idx = similarity.flatten().argsort()[::-1][:10]\n",
    "\n",
    "#menampilkan 10 dokumen yang paling mirip\n",
    "top_10_doc = df_cleaned.loc[top_10_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c32639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "address_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
